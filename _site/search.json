[
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "",
    "text": "In this article, we will convert a deep learning model to ONNX format. We will a Lightning module based on the Efficientnet B1 and we will export it to onyx format. We will show two approaches: 1) Standard torch way of exporting the model to ONNX 2) Export using a torch lighting method\nONNX is an open format built to represent machine learning models. ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers. It is adopted and developed by several top-tier tech companies, such as Facebook, Microsoft, Amazon, and others. Models in onyx format can be easily deployed to various cloud platforms as well as to IoT devices."
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#imports",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#imports",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Imports",
    "text": "Imports\n\nimport torch\nfrom torch import nn\nfrom torch.optim import lr_scheduler, Adam\nfrom torch.utils.data import DataLoader\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics import Recall, Accuracy\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom efficientnet_pytorch import EfficientNet\n\nimport os\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import classification_report\nimport numpy as np"
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#datamodule",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#datamodule",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Datamodule",
    "text": "Datamodule\n\nclass ImageClassificationDatamodule(pl.LightningDataModule):\n    def __init__(self, batch_size, train_transform, val_transform):\n        super().__init__()\n        self.batch_size = batch_size\n        self.train_transform = train_transform\n        self.val_transform = val_transform\n\n    def setup(self, stage=None):\n        self.train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=self.train_transform)\n\n        self.val_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=self.val_transform)\n\n    def train_dataloader(self):\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False, num_workers=4)"
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#lightning-module",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#lightning-module",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Lightning module",
    "text": "Lightning module\n\nclass ImageClassifier(pl.LightningModule):\n    lr = 1e-3\n\n    def __init__(self):\n        super().__init__()\n\n        self.criterion = nn.CrossEntropyLoss()\n        self.metrics = {\"accuracy\": Accuracy(), \"recall\": Recall()}\n\n        self.model = EfficientNet.from_pretrained('efficientnet-b1',\n                                                  num_classes=10,\n                                                  in_channels=3)\n\n    def forward(self, x):\n        return self.model(x)\n\n    def configure_optimizers(self):\n        optimizer = Adam(self.parameters(), self.lr)\n        scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n        return [optimizer], [scheduler]\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.forward(x)\n\n        loss = self.criterion(logits, y)\n\n        tensorboard_logs = {'train_loss': loss}\n\n        return {'loss': loss, 'log': tensorboard_logs}\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.forward(x)\n\n        loss = self.criterion(logits, y)\n\n        metrics_dict = {f\"val_{name}\": metric(logits, y) for name, metric in self.metrics.items()}\n\n        return {**{\"val_loss\": loss}, **metrics_dict}\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n\n        tensorboard_logs = {name: torch.stack([x[f\"val_{name}\"] for x in outputs]).mean()\n                            for name, metric in self.metrics.items()}\n\n        tensorboard_logs[\"val_loss\"] = avg_loss\n\n        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}"
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#training-loop",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#training-loop",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Training loop",
    "text": "Training loop\n\ntrain_transform = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\nval_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n\ndm = ImageClassificationDatamodule(128, train_transform, val_transform)\n\nmodel = ImageClassifier()\n\ncheckpoint_callback = ModelCheckpoint(\n    filepath=os.getcwd(),\n    save_top_k=1,\n    verbose=True,\n    monitor='val_loss',\n    mode='min',\n)\n\nTENSORBOARD_DIRECTORY = \"logs/\"\nEXPERIMENT_NAME = \"efficienet_b1\"\nlogger = TensorBoardLogger(TENSORBOARD_DIRECTORY, name=EXPERIMENT_NAME)\n\n#And then actual training\ntrainer = Trainer(max_epochs=10,\n                  logger=logger,\n                  gpus=1,\n                  # precision=16,\n                  accumulate_grad_batches=4,\n                  deterministic=True,\n                  early_stop_callback=True,\n                  checkpoint_callback=checkpoint_callback,\n                  # resume_from_checkpoint = 'my_checkpoint.ckpt'\n                  )\n\ntrainer.fit(model, dm)\n\nDownloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b1-f1951068.pth\n\n\n\n\n\n/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Checkpoint directory /content exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n  warnings.warn(*args, **kwargs)\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nCUDA_VISIBLE_DEVICES: [0]\n\n\n\nLoaded pretrained weights for efficientnet-b1\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n\n\n\n\n\nExtracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n\n\n\n  | Name      | Type             | Params\n-----------------------------------------------\n0 | criterion | CrossEntropyLoss | 0     \n1 | model     | EfficientNet     | 6 M   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 00000: val_loss reached 1.04839 (best 1.04839), saving model to /content/epoch=0.ckpt as top 1\n\n\n\n\n\n\nEpoch 00001: val_loss reached 0.81029 (best 0.81029), saving model to /content/epoch=1.ckpt as top 1\n\n\n\n\n\n\nEpoch 00002: val_loss reached 0.65911 (best 0.65911), saving model to /content/epoch=2.ckpt as top 1\n\n\n\n\n\n\nEpoch 00003: val_loss reached 0.63399 (best 0.63399), saving model to /content/epoch=3.ckpt as top 1\n\n\n\n\n\n\nEpoch 00004: val_loss reached 0.56925 (best 0.56925), saving model to /content/epoch=4.ckpt as top 1\n\n\n\n\n\n\nEpoch 00005: val_loss reached 0.54162 (best 0.54162), saving model to /content/epoch=5.ckpt as top 1\n\n\n\n\n\n\nEpoch 00006: val_loss reached 0.52157 (best 0.52157), saving model to /content/epoch=6.ckpt as top 1\n\n\n\n\n\n\nEpoch 00007: val_loss reached 0.46342 (best 0.46342), saving model to /content/epoch=7.ckpt as top 1\n\n\n\n\n\n\nEpoch 00008: val_loss reached 0.45730 (best 0.45730), saving model to /content/epoch=8.ckpt as top 1\n\n\n\n\n\n\nEpoch 00009: val_loss reached 0.45397 (best 0.45397), saving model to /content/epoch=9.ckpt as top 1\nSaving latest checkpoint..\n\n\n\n\n\n1"
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#show-some-training-statistics",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#show-some-training-statistics",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Show some training statistics",
    "text": "Show some training statistics\n\n%load_ext tensorboard\n%tensorboard --logdir logs\n\n\n\n\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n\nval_dl = DataLoader(torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transform), batch_size=128, shuffle=True, num_workers=4)\n\nFiles already downloaded and verified\n\n\n\nmodel.to(\"cuda\")\nmodel.eval()\nprint()\n\n\n\n\n\npredictions = []\ntargets = []\nfor X, y in tqdm(val_dl):\n    outputs = torch.nn.Softmax(dim=1)(model(X.to(\"cuda\")))\n    _, predicted = torch.max(outputs, 1)\n    predictions.append(predicted.detach())\n    targets.append(y.detach())\n\n\n\n\n\n\n\n\npredictions = (torch.cat(predictions)).cpu().numpy() \ntargets = (torch.cat(targets)).cpu().numpy()\n\n\nprint(classification_report(targets, predictions, target_names=classes))\n\n              precision    recall  f1-score   support\n\n       plane       0.84      0.86      0.85      1000\n         car       0.93      0.91      0.92      1000\n        bird       0.84      0.78      0.81      1000\n         cat       0.69      0.72      0.70      1000\n        deer       0.79      0.85      0.82      1000\n         dog       0.80      0.72      0.76      1000\n        frog       0.87      0.92      0.90      1000\n       horse       0.90      0.86      0.88      1000\n        ship       0.90      0.91      0.90      1000\n       truck       0.88      0.90      0.89      1000\n\n    accuracy                           0.84     10000\n   macro avg       0.84      0.84      0.84     10000\nweighted avg       0.84      0.84      0.84     10000"
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#do-the-example-prediction",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#do-the-example-prediction",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Do the example prediction",
    "text": "Do the example prediction\nONNX needs some input data, so it knows its shape. Since we already have a dataloader we don’t need to create dummy random data of the wanted shape\n\nX, y = next(iter(val_dl))\nprint(f\"Model input: {X.size()}\")\ntorch_out = model(X.to(\"cuda\"))\nprint(f\"Model output: {torch_out.detach().cpu().size()}\")\n\nModel input: torch.Size([128, 3, 32, 32])\nModel output: torch.Size([128, 10])"
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#convert-model-to-onnx---standard-torch-approach",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#convert-model-to-onnx---standard-torch-approach",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Convert model to ONNX - standard torch approach",
    "text": "Convert model to ONNX - standard torch approach\nInspired by: https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html\nWe export the PyTorch Lightning model similarly as we would do with a normal torch model\n\n## a necessary fix, applicable only for Efficientnet\nmodel.model.set_swish(memory_efficient=False)\n\n\n# # Export the model\ntorch.onnx.export(model,                     # model being run\n                  ##since model is in the cuda mode, input also need to be\n                  X.to(\"cuda\"),              # model input (or a tuple for multiple inputs)\n                  \"model_troch_export.onnx\", # where to save the model (can be a file or file-like object)\n                  export_params=True,        # store the trained parameter weights inside the model file\n                  opset_version=10,          # the ONNX version to export the model to\n                  do_constant_folding=True,  # whether to execute constant folding for optimization\n                  input_names = ['input'],   # the model's input names\n                  output_names = ['output'], # the model's output names\n                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n                                'output' : {0 : 'batch_size'}})\n\n\nls\n\n data/  'epoch=9.ckpt'   logs/   model_troch_export.onnx   sample_data/"
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#convert-model-to-onnx---standard-torch-approach-1",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#convert-model-to-onnx---standard-torch-approach-1",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Convert model to ONNX - standard torch approach",
    "text": "Convert model to ONNX - standard torch approach\nPyTorch Lightning has its own method for exporting the model. The arguments are similar as in torch.onnx.export method\n\n## a necessary fix, applicable only for Efficientnet\nmodel.model.set_swish(memory_efficient=False)\n\n\nmodel.to_onnx(\"model_lightnining_export.onnx\", \n                X.to(\"cuda\"),\n                export_params=True,\n                input_names = ['input'],  \n                output_names = ['output'], \n                dynamic_axes={'input' : {0 : 'batch_size'},'output' : {0 : 'batch_size'}})\n\n\nls\n\n data/           logs/                           model_troch_export.onnx\n'epoch=9.ckpt'   model_lightnining_export.onnx   sample_data/"
  },
  {
    "objectID": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#do-the-prediction-with-onnx",
    "href": "posts/2020-09-21-exporting-lightning-model-to-onnx.html#do-the-prediction-with-onnx",
    "title": "Exporting PyTorch Lightning model to ONNX format",
    "section": "Do the prediction with ONNX",
    "text": "Do the prediction with ONNX\nSince we want to do the predicton on the GPU we need to make sure that CUDA is avaible as onnxruntime provider and is a first provider\n\nimport onnxruntime\nimport onnx\n\nort_session = onnxruntime.InferenceSession(\"model_lightnining_export.onnx\")\n\nort_session.get_providers()\n\n['CUDAExecutionProvider', 'CPUExecutionProvider']\n\n\n\nonnx_model = onnx.load(\"model_lightnining_export.onnx\")\nonnx.checker.check_model(onnx_model)\n\n\ndef to_numpy(tensor):\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n\n##We set the batch size to the dynamic_axes, so we can use batch of any size we like, 10 in this example\n# compute ONNX Runtime output prediction\nort_inputs = {ort_session.get_inputs()[0].name: to_numpy(X[:10])} \nort_outs = ort_session.run(None, ort_inputs)\n\n# compare ONNX Runtime and PyTorch results\nnp.testing.assert_allclose(to_numpy(torch_out[:10]), ort_outs[0], rtol=1e-03, atol=1e-05)\n\nprint(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\n\nExported model has been tested with ONNXRuntime, and the result looks good!\n\n\n\nort_outs[0].shape\n\n(10, 10)"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html",
    "href": "posts/2020-09-09-lime-biased-dataset.html",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "",
    "text": "In 2016 Marco Riberio et al. proposed a new method for explaining AI models named LIME. Abbreviation LIME stands for Local Interpretable Model-Agnostic Explanations. The algorithm is capable of explaining any type of machine-learning model (that’s why it is called “model agnostic) and works well with tabular, language, and image data.\nThe LIME algorithm is available in the form of a python package, its code can be found on the Github at https://github.com/marcotcr/lime\nIn this tutorial, we will show how LIME can be applied to investigate the deep learning model behavior. We will show that despite the model achieving good accuracy on a validation set it actually doesn’t work. Such behavior is caused by a biased dataset and may cause real harm when the model is used for real-world applications. It may be especially dangerous in the case of medical imagining where it is nearly impossible for a non-medical professional to say whether or not the analyzed dataset of x-ray images is somehow biased.\nThe proposed pet dataset contains two classes: Huskies and Wolves. The gathered data are intentionally biased - wolfs are always presented in a winter background with snow around them, while husky stand or lay on the grass. Even though it sounds obvious that such a dataset may cause a model to not perform well, it is still not so easy to spot this fact at a first glance, without having the prior knowledge about what is wrong. Riberio et al. gave such a dataset to the group of graduate students and only a minority of them spot the problem. Most of the students trusted the model based only on the accuracy metric.\nThe train set consists of 50 images of huskies and 50 images of wolfs. The validation set contains 5 images of huskies and 5 images of wolfs. In the validation set 8 images to come from a similar domain as the training set (a husky on the grass, a wolf in the snow) while in the case of two we intentionally changed the usual background (husky on the snow and wolf on the grass).\nIn this tutorial, we first train the torch model (resnet50) on the dataset, and then we use LIME to see which part of the image had the most significant contrubution to such prediction. The intuition behind is: if the model “looks” at the irrelevant part of the image then even if it is highly accurate on the validation set it probably doesn’t work properly. The reason for that might be a biased dataset. In this case (wolf and husks) is relatively easy even for a layman to spot a problem, however, for a more complicated task (eg. classification of tumors on the images), it may be a highly complicated problem requiring lots of research and domain knowledge."
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#imports",
    "href": "posts/2020-09-09-lime-biased-dataset.html#imports",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Imports",
    "text": "Imports\n\nfrom os import listdir\nfrom os.path import join\nfrom torchvision import transforms\n\nimport torch\nfrom torch.optim import lr_scheduler\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport pytorch_lightning as pl\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom skimage.segmentation import mark_boundaries\nfrom lime import lime_image\n\nfrom lime_image.dataset import HuskyWolfDataset\nfrom lime_image.datamodule import HuskyWolfDataModule\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\nfrom PIL import Image\n\n\nfrom sklearn.metrics import accuracy_score"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#directories-with-gathered-datasets",
    "href": "posts/2020-09-09-lime-biased-dataset.html#directories-with-gathered-datasets",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Directories with gathered datasets",
    "text": "Directories with gathered datasets\n\nhusky_train_path = join(\"lime_image\", \"husky_train\")\nwolf_train_path = join(\"lime_image\", \"wolf_train\")\n\nhusky_test_path = join(\"lime_image\", \"husky_test\")\nwolf_test_path = join(\"lime_image\", \"wolf_test\")"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#husky-train",
    "href": "posts/2020-09-09-lime-biased-dataset.html#husky-train",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Husky train",
    "text": "Husky train\n\nfiles = [(join(husky_train_path, file)) for file in listdir(husky_train_path)]\n\nimshow(Image.open(files[0]).resize((244, 244)))\nplt.show()\n\nimshow(Image.open(files[1]).resize((244, 244)))\nplt.show()\n\nimshow(Image.open(files[2]).resize((244, 244)))\nplt.show()"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#husky-test",
    "href": "posts/2020-09-09-lime-biased-dataset.html#husky-test",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Husky test",
    "text": "Husky test\n\nfiles = [(join(husky_test_path, file)) for file in listdir(husky_test_path)]\n\nimshow(Image.open(files[0]).resize((244, 244)))\nplt.show()\n\nimshow(Image.open(files[1]).resize((244, 244)))\nplt.show()\n\nimshow(Image.open(files[4]).resize((244, 244)))\nplt.show()"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#wofl-train",
    "href": "posts/2020-09-09-lime-biased-dataset.html#wofl-train",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Wofl train",
    "text": "Wofl train\n\nfiles = [(join(wolf_train_path, file)) for file in listdir(wolf_train_path)]\n\nimshow(Image.open(files[0]).resize((244, 244)))\nplt.show()\n\nimshow(Image.open(files[1]).resize((244, 244)))\nplt.show()\n\nimshow(Image.open(files[2]).resize((244, 244)))\nplt.show()"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#wofl-test",
    "href": "posts/2020-09-09-lime-biased-dataset.html#wofl-test",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Wofl test",
    "text": "Wofl test\n\nfiles = [(join(wolf_test_path, file)) for file in listdir(wolf_test_path)]\n\nimshow(Image.open(files[0]).resize((244, 244)))\nplt.show()\n\nimshow(Image.open(files[1]).resize((244, 244)))\nplt.show()\n\nimshow(Image.open(files[2]).resize((244, 244)))\nplt.show()"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#define-the-model",
    "href": "posts/2020-09-09-lime-biased-dataset.html#define-the-model",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Define the model",
    "text": "Define the model\nAs a base model, we will use resnet50. We will train it using PyTorch Lighting. Since our dataset is relatively small we will use the transfer learning technique and train only the last layer.\n\nclass WolfHuskyClassifier(pl.LightningModule):\n    def __init__(self):\n        super(WolfHuskyClassifier, self).__init__()\n        self.criterion = nn.CrossEntropyLoss()\n        \n        self.model = models.resnet50(pretrained=True)\n        \n        ## Only the last layer is trained\n        for p in self.model.parameters():\n            p.requires_grad = False\n\n        self.num_ftrs = self.model.fc.in_features\n        self.number_of_classes = 2\n        self.model.fc = nn.Linear(self.num_ftrs, self.number_of_classes)\n    \n    \n    def forward(self, x):\n        return self.model(x)\n\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n        \n        return [optimizer], [scheduler]\n    \n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        \n        logits = self.forward(x)\n        loss = self.criterion(logits, y)\n        \n        tensorboard_logs = {'train_loss': loss}\n        \n        return {'loss': loss, 'log': tensorboard_logs}\n\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n\n        logits = self.forward(x)\n        loss = self.criterion(logits, y)\n        \n        return {\"val_loss\": loss}\n        \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        \n        tensorboard_logs = {\"val_loss\" : avg_loss}\n\n        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#image-augmentations",
    "href": "posts/2020-09-09-lime-biased-dataset.html#image-augmentations",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Image augmentations",
    "text": "Image augmentations\nTo artificially extend the dataset we will use random image transformations. To make it more “understandable” for a model we have to normalize it (we use standard ImageNet mean and std parameters).\n\nval_transform = A.Compose([\n            A.Resize(224, 224),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ToTensorV2()\n            ])\n\n\ntrain_transform = A.Compose([\n            A.Resize(400, 400),\n            A.RandomCrop(224, 224),\n            A.HorizontalFlip(),\n            A.RandomRotate90(),\n            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n            A.Blur(blur_limit=3),\n            A.OpticalDistortion(),\n            A.GridDistortion(),\n            A.HueSaturationValue(),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2()\n        ])"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#start-training",
    "href": "posts/2020-09-09-lime-biased-dataset.html#start-training",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Start training",
    "text": "Start training\n\npl.seed_everything(42)\n\ndm = HuskyWolfDataModule(2, train_transform, val_transform)\n\nmodel = WolfHuskyClassifier()\n\ntrainer = pl.Trainer(max_epochs=20,\n                  gpus=0,\n                  accumulate_grad_batches=4,\n                  deterministic=True,\n                  early_stop_callback=True,\n                  )\n\ntrainer.fit(model, dm)\n\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\n\n  | Name      | Type             | Params\n-----------------------------------------------\n0 | criterion | CrossEntropyLoss | 0     \n1 | model     | ResNet           | 23 M  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSaving latest checkpoint..\nEpoch 00015: early stopping triggered.\n\n\n\n\n\n1"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#check-the-model-performance",
    "href": "posts/2020-09-09-lime-biased-dataset.html#check-the-model-performance",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Check the model performance",
    "text": "Check the model performance\n\nwolf_husky_trainset = HuskyWolfDataset([husky_train_path, wolf_train_path], val_transform)\nwolf_husky_testset = HuskyWolfDataset([husky_test_path, wolf_test_path], val_transform)\n\n\nmodel.eval()\n\ny_pred = []\ny_true = []\nfor img, label in wolf_husky_trainset:\n    pred = torch.argmax(model(img.unsqueeze(0)))\n    y_pred.append(pred)\n    y_true.append(label)\n    \nprint(f\"Accuracy on train: {accuracy_score(y_true, y_pred)}\")    \nprint()\n\nwrong_preds = []\n\ny_pred = []\ny_true = []\nfor idx, (img, label) in enumerate(wolf_husky_testset):\n    pred = torch.argmax(model(img.unsqueeze(0)))\n      \n    if pred != label:\n        wrong_preds.append(idx)\n        \n    y_pred.append(pred)\n    y_true.append(label)\n      \nprint()      \nprint(f\"Accuracy on validation: {accuracy_score(y_true, y_pred)}\")\nprint()      \nprint(f\"Wrong preds: {wrong_preds}\")\n\nAccuracy on train: 1.0\n\n\nAccuracy on validation: 0.9090909090909091\n\nWrong preds: [6]"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#visualize-the-explaination",
    "href": "posts/2020-09-09-lime-biased-dataset.html#visualize-the-explaination",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Visualize the explaination",
    "text": "Visualize the explaination\nAs we can see it was the background that contributed most to the prediction (the green field). Actually the relevant part - the body of the wolf, correctly “voted” against image be classified as a husky. Despite that, the contribution of grass was more significant and the image was classified incorrectly.\nNevertheless, regardless of the final prediction, we can see that there is something inherently wrong about the model. It focuses itself on the irrelevant pieces of data and mostly ignores the relevant. It should be an alarming sound for any machine-learning practitioner that maybe something in the training process (presumably the data) is not correct.\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\nimg_boundry1 = mark_boundaries(temp/255.0, mask)\n\nplt.title(title)\nplt.imshow(img_boundry1)\n\n<matplotlib.image.AxesImage at 0x7f77e2fa00d0>\n\n\n\n\n\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\nimg_boundry2 = mark_boundaries(temp/255.0, mask)\n\nplt.title(title)\nplt.imshow(img_boundry2)\n\n<matplotlib.image.AxesImage at 0x7f77c81b94f0>"
  },
  {
    "objectID": "posts/2020-09-09-lime-biased-dataset.html#ok-how-about-explainations-for-another-images",
    "href": "posts/2020-09-09-lime-biased-dataset.html#ok-how-about-explainations-for-another-images",
    "title": "Is it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model",
    "section": "Ok, how about explainations for another images",
    "text": "Ok, how about explainations for another images\nLet us take 5 examples both classified correctly and let’s use LIME to see at what the trained model is “looking” in the decision-making process.\nUnsurprisingly in all cases, the background (grass/snow) has a significant impact on the outcome, which, as it was stated before should not be the case. On the other hand, we can see that our model is not totally useless. While making the decision, in some cases it still “looks” at the body of the animal, this can be a positive sing meaning that in case we provide the neural network with a less biased and more diverse data it might be able to classify the dataset correctly.\n\ninvestigated_img_0, real_label_0 = visualisation_testset[5]\ninvestigated_img_1, real_label_1 = visualisation_testset[0]\ninvestigated_img_2, real_label_2 = visualisation_testset[3]\ninvestigated_img_3, real_label_3 = visualisation_testset[7]\ninvestigated_img_4, real_label_4 = visualisation_testset[9]\n\n\ntest_pred = batch_predict([investigated_img_0, investigated_img_1, investigated_img_2, investigated_img_3, investigated_img_4])\npreds = test_pred.squeeze().argmax(axis=1)\nprint(f\"Predictions: {preds}\")\nprint(f\"Real Labels: {real_label_0.item(), real_label_1.item(), real_label_2.item(), real_label_3.item(), real_label_4.item()}\")\n\nPredictions: [1 0 0 1 1]\nReal Labels: (1, 0, 0, 1, 1)\n\n\n\nexplainer = lime_image.LimeImageExplainer()\nexplanation = explainer.explain_instance(\n                                         investigated_img_0,\n                                         batch_predict, # classification function\n                                         top_labels=1, \n                                         hide_color=0, \n                                         num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\nimg_boundry1 = mark_boundaries(temp/255.0, mask)\n\ntitle = f\"Prediction {label_to_class[preds[0]]}, Real label: {label_to_class[real_label_0.item()]}\"\n\nplt.title(title)\nplt.imshow(img_boundry1)\nplt.show()\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\nimg_boundry2 = mark_boundaries(temp/255.0, mask)\n\nplt.title(title)\nplt.imshow(img_boundry2)\n\n\n\n\n\n\n\n\n\n\n<matplotlib.image.AxesImage at 0x7f77e2f47970>\n\n\n\n\n\n\nexplainer = lime_image.LimeImageExplainer()\nexplanation = explainer.explain_instance(\n                                         investigated_img_1,\n                                         batch_predict, # classification function\n                                         top_labels=1, \n                                         hide_color=0, \n                                         num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\nimg_boundry1 = mark_boundaries(temp/255.0, mask)\n\ntitle = f\"Prediction {label_to_class[preds[1]]}, Real label: {label_to_class[real_label_1.item()]}\"\nplt.title(title)\nplt.imshow(img_boundry1)\nplt.show()\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\nimg_boundry2 = mark_boundaries(temp/255.0, mask)\n\nplt.title(f\"Prediction {preds[1]}, Real label: {real_label_1} \")\nplt.imshow(img_boundry2)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexplainer = lime_image.LimeImageExplainer()\nexplanation = explainer.explain_instance(\n                                         investigated_img_2,\n                                         batch_predict, # classification function\n                                         top_labels=1, \n                                         hide_color=0, \n                                         num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\nimg_boundry1 = mark_boundaries(temp/255.0, mask)\n\ntitle = f\"Prediction {label_to_class[preds[2]]}, Real label: {label_to_class[real_label_2.item()]}\"\nplt.title(title)\nplt.imshow(img_boundry1)\nplt.show()\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\nimg_boundry2 = mark_boundaries(temp/255.0, mask)\n\nplt.title(f\"Prediction {preds[2]}, Real label: {real_label_2} \")\nplt.imshow(img_boundry2)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexplainer = lime_image.LimeImageExplainer()\nexplanation = explainer.explain_instance(\n                                         investigated_img_3,\n                                         batch_predict, # classification function\n                                         top_labels=1, \n                                         hide_color=0, \n                                         num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\nimg_boundry1 = mark_boundaries(temp/255.0, mask)\n\ntitle = f\"Prediction {label_to_class[preds[3]]}, Real label: {label_to_class[real_label_3.item()]}\"\nplt.title(title)\nplt.imshow(img_boundry1)\nplt.show()\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\nimg_boundry2 = mark_boundaries(temp/255.0, mask)\n\nplt.title(title)\nplt.imshow(img_boundry2)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexplainer = lime_image.LimeImageExplainer()\nexplanation = explainer.explain_instance(\n                                         investigated_img_4,\n                                         batch_predict, # classification function\n                                         top_labels=1, \n                                         hide_color=0, \n                                         num_samples=1000)\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\nimg_boundry1 = mark_boundaries(temp/255.0, mask)\n\ntitle = f\"Prediction {label_to_class[preds[4]]}, Real label: {label_to_class[real_label_4.item()]}\"\nplt.title(title)\nplt.imshow(img_boundry1)\nplt.show()\n\ntemp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\nimg_boundry2 = mark_boundaries(temp/255.0, mask)\n\nplt.title(title)\nplt.imshow(img_boundry2)\nplt.show()"
  },
  {
    "objectID": "nbs/00_core.html",
    "href": "nbs/00_core.html",
    "title": "tugot-blog",
    "section": "",
    "text": "core\n\nFill in a module description here\n\n::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\nfrom nbdev.showdoc import *\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef foo(): pass\n:::\n::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\nimport nbdev; nbdev.nbdev_export()\n:::"
  },
  {
    "objectID": "nbs/index.html",
    "href": "nbs/index.html",
    "title": "tugot-blog",
    "section": "",
    "text": "::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}\n:::"
  },
  {
    "objectID": "nbs/index.html#install",
    "href": "nbs/index.html#install",
    "title": "tugot-blog",
    "section": "Install",
    "text": "Install\npip install data_science_blog"
  },
  {
    "objectID": "nbs/index.html#how-to-use",
    "href": "nbs/index.html#how-to-use",
    "title": "tugot-blog",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "tugot-blog",
    "section": "",
    "text": "Exporting PyTorch Lightning model to ONNX format\n\n\n\n\n\n\n\nONNX\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2020\n\n\n\n\n\n\n\n\nIs it a wolf or is it snow? Using the LIME algorithm to investigate the bias in the decision-making process of a deep learning model\n\n\n\n\n\n\n\nXAI\n\n\nLIME\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2020\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]